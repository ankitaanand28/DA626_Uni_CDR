{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils.GraphMaker import GraphMaker\n",
    "from model.trainer import CrossTrainer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import pdb\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'utils')\n",
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arg_parser():\n",
    "    \"\"\"Create argument parser for our baseline. \"\"\"\n",
    "    parser = argparse.ArgumentParser('WSDM')\n",
    "\n",
    "    # DATA  Arguments\n",
    "    parser.add_argument('--domains', type=str, default='d1_d2_d3', help='specify none (\"none\") or a few source markets (\"-\" seperated) to augment the data for training')\n",
    "    parser.add_argument('--task', type=str, default='multi-user-intra', help='dual-user-intra, dual-user-inter, multi-item-intra, multi-user-intra')\n",
    "\n",
    "    # MODEL Arguments\n",
    "    parser.add_argument('--model', type=str, default='UniCDR', help='right model name')\n",
    "    parser.add_argument('--mask_rate', type=float, default=0.1, help='mask rate of interactions')\n",
    "    parser.add_argument('--num_epoch', type=int, default=100, help='number of epoches')\n",
    "    parser.add_argument('--aggregator', type=str, default='mean', help='switching the user-item aggregation')\n",
    "    parser.add_argument('--batch_size', type=int, default=1024, help='batch size')\n",
    "    parser.add_argument('--optim', choices=['sgd', 'adagrad', 'adam', 'adamax'], default='adam',\n",
    "                        help='Optimizer: sgd, adagrad, adam or adamax.')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "    parser.add_argument('--l2_reg', type=float, default=1e-7, help='the L2 weight')\n",
    "    parser.add_argument('--lr_decay', type=float, default=0.98, help='decay learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-5, help='decay learning rate')\n",
    "    parser.add_argument('--latent_dim', type=int, default=128, help='latent dimensions')\n",
    "    parser.add_argument('--num_negative', type=int, default=10, help='num of negative samples during training')\n",
    "    parser.add_argument('--maxlen', type=int, default=10, help='num of item sequence')\n",
    "    parser.add_argument('--dropout', type=float, default=0.3, help='random drop out rate')\n",
    "    parser.add_argument('--save',default='save', action='store_true', help='save model?')\n",
    "    parser.add_argument('--lambda', type=float, default=50, help='the parameter of EASE')\n",
    "    parser.add_argument('--lambda_a', type=float, default=0.5, help='for our aggregators')\n",
    "    parser.add_argument('--lambda_loss', type=float, default=0.4, help='the parameter of loss function')\n",
    "    parser.add_argument('--static_sample', default='static_sample',action='store_true', help='accelerate the dataloader')\n",
    "\n",
    "    # others\n",
    "    parser.add_argument('--cuda',default='cuda', action='store_true', help='use of cuda')\n",
    "    parser.add_argument('--seed', type=int, default=42, help='manual seed init')\n",
    "    parser.add_argument('--decay_epoch', type=int, default=10, help='Decay learning rate after this epoch.')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = create_arg_parser()\n",
    "opt, _ = parser.parse_known_args()  # Ignore unknown arguments\n",
    "opt = vars(opt)\n",
    "\n",
    "opt[\"device\"] = torch.device('cuda' if torch.cuda.is_available() and opt[\"cuda\"] else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running with the following configs:\n",
      "\tdomains : d1_d2_d3\n",
      "\ttask : multi-user-intra\n",
      "\tmodel : UniCDR\n",
      "\tmask_rate : 0.1\n",
      "\tnum_epoch : 100\n",
      "\taggregator : mean\n",
      "\tbatch_size : 1024\n",
      "\toptim : adam\n",
      "\tlr : 0.001\n",
      "\tl2_reg : 1e-07\n",
      "\tlr_decay : 0.98\n",
      "\tweight_decay : 1e-05\n",
      "\tlatent_dim : 128\n",
      "\tnum_negative : 10\n",
      "\tmaxlen : 50\n",
      "\tdropout : 0.3\n",
      "\tsave : save\n",
      "\tlambda : 50\n",
      "\tlambda_a : 0.5\n",
      "\tlambda_loss : 0.4\n",
      "\tstatic_sample : static_sample\n",
      "\tcuda : cuda\n",
      "\tseed : 42\n",
      "\tdecay_epoch : 10\n",
      "\tdevice : cuda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_config(config):\n",
    "        info = \"Running with the following configs:\\n\"\n",
    "        for k, v in config.items():\n",
    "            info += \"\\t{} : {}\\n\".format(k, str(v))\n",
    "        print(\"\\n\" + info + \"\\n\")\n",
    "\n",
    "if opt[\"task\"] == \"multi-user-intra\":\n",
    "        opt[\"maxlen\"] = 50\n",
    "\n",
    "print_config(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'Running experiment on device: {opt[\"device\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1111):\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(opt[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d1_d2_d3'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[\"domains\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading domains: ['d1', 'd2', 'd3']\n"
     ]
    }
   ],
   "source": [
    "if \"dual\" in opt[\"task\"]:\n",
    "        filename = opt[\"domains\"].split(\"_\")\n",
    "        opt[\"domains\"] = []\n",
    "        opt[\"domains\"].append(filename[0] + \"_\" + filename[1])\n",
    "        opt[\"domains\"].append(filename[1] + \"_\" + filename[0])\n",
    "\n",
    "\n",
    "else:\n",
    "        opt[\"domains\"] = opt[\"domains\"].split('_')\n",
    "\n",
    "print(\"Loading domains:\", opt[\"domains\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = opt[\"domains\"]\n",
    "opt[\"user_max\"] = []\n",
    "opt[\"item_max\"] = []\n",
    "task_gen_all = {}\n",
    "domain_id = {}\n",
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading d1: datasets/multi-user-intra/dataset/d1/train.txt\n",
      "datasets/multi-user-intra/dataset/d1/train.txt\n",
      "d1\n",
      "['d1', 'd2', 'd3']\n",
      "Loading d2: datasets/multi-user-intra/dataset/d2/train.txt\n",
      "datasets/multi-user-intra/dataset/d2/train.txt\n",
      "d2\n",
      "['d1', 'd2', 'd3']\n",
      "Loading d3: datasets/multi-user-intra/dataset/d3/train.txt\n",
      "datasets/multi-user-intra/dataset/d3/train.txt\n",
      "d3\n",
      "['d1', 'd2', 'd3']\n",
      "begin graphmaker................\n",
      "The alignment id 0 0\n",
      "231444 2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\utils\\GraphMaker.py:14: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alignment id 0 2096\n",
      "647482 596\n",
      "The alignment id 0 2691\n",
      "1104098 1313\n",
      "graphmaker done.........\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        \n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        max_user = 0\n",
    "        max_item = 0\n",
    "        print(cur_src_data_dir)\n",
    "        print(cur_domain)\n",
    "        print(opt[\"domains\"])\n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter+=1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                max_user = max(max_user, user)\n",
    "                max_item = max(max_item, item)\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    all_domain_list[idx][user].append(item)\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        opt[\"user_max\"].append(max_user + 1)\n",
    "        opt[\"item_max\"].append(max_item + 1)\n",
    "\n",
    "total_graphs = GraphMaker(opt, all_domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading d1: datasets/multi-user-intra/dataset/d1/train.txt\n",
      "Loading d1: datasets/multi-user-intra/dataset/d1/train.txt\n",
      "the min/max user/item number of  datasets/multi-user-intra/dataset/d1/train.txt\n",
      "user: 0 231443\n",
      "item: 1 2096\n",
      "Loading d2: datasets/multi-user-intra/dataset/d2/train.txt\n",
      "Loading d2: datasets/multi-user-intra/dataset/d2/train.txt\n",
      "the min/max user/item number of  datasets/multi-user-intra/dataset/d2/train.txt\n",
      "user: 4 647481\n",
      "item: 1 595\n",
      "Loading d3: datasets/multi-user-intra/dataset/d3/train.txt\n",
      "Loading d3: datasets/multi-user-intra/dataset/d3/train.txt\n",
      "the min/max user/item number of  datasets/multi-user-intra/dataset/d3/train.txt\n",
      "user: 4 1104097\n",
      "item: 1 1312\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "\n",
    "        if opt[\"aggregator\"] == \"item_similarity\":\n",
    "            ease_dense = total_graphs.ease[idx].to_dense()\n",
    "\n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        \n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter += 1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    if opt[\"aggregator\"] == \"item_similarity\":\n",
    "                        all_domain_list[idx][user].append([item, ease_dense[user][item]])\n",
    "                    else:\n",
    "                        all_domain_list[idx][user].append([item, 1])\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        cur_src_task_generator = TaskGenerator(cur_src_data_dir, opt, all_domain_list, all_domain_set, idx,\n",
    "                                               total_graphs)\n",
    "        task_gen_all[idx] = cur_src_task_generator\n",
    "        domain_id[cur_domain] = idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_domains = MetaDomain_Dataset(task_gen_all, num_negatives=opt[\"num_negative\"], meta_split='train')\n",
    "train_dataloader = MetaDomain_DataLoader(train_domains, sample_batch_size=opt[\"batch_size\"] // len(domain_list), shuffle=True)\n",
    "opt[\"num_domains\"] = train_dataloader.num_domains\n",
    "opt[\"domain_id\"] = domain_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the evaluation data:  datasets/multi-user-intra/dataset/d1/valid.txt\n",
      "datasets/multi-user-intra/dataset/d1/valid.txt valid user:  10548\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d1/test.txt\n",
      "datasets/multi-user-intra/dataset/d1/test.txt valid user:  10549\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d2/valid.txt\n",
      "datasets/multi-user-intra/dataset/d2/valid.txt valid user:  31572\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d2/test.txt\n",
      "datasets/multi-user-intra/dataset/d2/test.txt valid user:  31573\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d3/valid.txt\n",
      "datasets/multi-user-intra/dataset/d3/valid.txt valid user:  80457\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d3/test.txt\n",
      "datasets/multi-user-intra/dataset/d3/test.txt valid user:  80457\n",
      "the user number of different domains [231444, 647482, 1104098]\n",
      "the item number of different domains [2097, 596, 1313]\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## Validation and Test\n",
    "############\n",
    "if \"inter\" in opt[\"task\"]:\n",
    "    opt[\"shared_user\"] = 1e9\n",
    "valid_dataloader = {}\n",
    "test_dataloader = {}\n",
    "for cur_domain in domain_list:\n",
    "        if opt[\"task\"] == \"dual-user-intra\":\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        else:\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/valid.txt\")\n",
    "        domain_test = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        valid_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_valid, 100)\n",
    "        test_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_test, 100)\n",
    "\n",
    "print(\"the user number of different domains\", opt[\"user_max\"])\n",
    "print(\"the item number of different domains\", opt[\"item_max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.GraphMaker import GraphMaker\n",
    "from model.trainer import CrossTrainer\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define paths to saved weights and dataset\n",
    "model_weights_path = 'Trained_Model\\model_d1d2d3_epoch_5.pt'\n",
    "\n",
    "\n",
    "# Initialize model with the same architecture as training\n",
    "model = CrossTrainer(opt)  # `opt` should be the same dictionary used during training\n",
    "\n",
    "\n",
    "\n",
    "# Load the model using the custom `load()` method of CrossTrainer\n",
    "model.load(model_weights_path)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.model.eval()\n",
    "\n",
    "# Load and preprocess the dataset using GraphMaker\n",
    "graph_maker = total_graphs\n",
    "UV_adj, VU_adj, ease_pred = graph_maker.UV, graph_maker.VU, graph_maker.ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on particular example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of UV_adj: 3\n",
      "Length of VU_adj: 3\n",
      "Length of ease_pred: 3\n",
      "User index: tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define user index and item indices for inference\n",
    "user_idx = torch.tensor([1], dtype=torch.long).to(device)  # Move user index to the same device\n",
    "item_indices = torch.tensor([1, 2,4, 6], dtype=torch.long).to(device)  # Move item indices to the same device\n",
    "print(f\"Length of UV_adj: {len(UV_adj)}\")\n",
    "print(f\"Length of VU_adj: {len(VU_adj)}\")\n",
    "print(f\"Length of ease_pred: {len(ease_pred)}\")\n",
    "print(f\"User index: {user_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': 0, 'd2': 1, 'd3': 2}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['domain_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended items for user: tensor([2, 1, 0, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Ensure item embeddings are initialized (fix for con_item_emb_list)\n",
    "model.model.item_embedding_select()\n",
    "\n",
    "# Specify a domain to run inference on, here it's 'game_video' and 'video_game'\n",
    "domain_id = opt['domain_id']['d1']  # Change based on domain\n",
    "\n",
    "# Define user index and item indices for inference\n",
    "user_idx = torch.tensor([0], dtype=torch.long).to(device)  # Move user index to the same device\n",
    "item_indices = torch.tensor([1,2, 4, 6], dtype=torch.long).to(device)  # Move item indices to the same device\n",
    "\n",
    "# Ensure user_idx is valid\n",
    "if user_idx >= len(UV_adj) or user_idx >= len(VU_adj) or user_idx >= len(ease_pred):\n",
    "    raise ValueError(f\"user_idx {user_idx} is out of bounds for the dataset.\")\n",
    "# Define dummy context and global scores, and move them to the correct device\n",
    "context_item = torch.zeros((1, 10), dtype=torch.long).to(device)  # Adjust based on your model\n",
    "context_score = torch.zeros((1, 10), dtype=torch.float).to(device)  # Adjust based on your model\n",
    "global_item = torch.zeros((1, len(item_indices), len(item_indices)), dtype=torch.long).to(device)  # Adjust shape\n",
    "global_score = torch.zeros((1, len(item_indices)), dtype=torch.float).to(device)  # Adjust shape\n",
    "\n",
    "# Get user embeddings using the model\n",
    "user_embedding = model.model.forward_user(domain_id, user_idx, context_item, context_score, global_item, global_score)\n",
    "\n",
    "# Get item embeddings using the model\n",
    "item_embeddings = model.model.forward_item(domain_id, item_indices)\n",
    "\n",
    "# Use the predict_dot method to generate the predictions (dot product of user and item embeddings)\n",
    "scores = model.model.predict_dot(user_embedding, item_embeddings)\n",
    "\n",
    "# Sort the scores to get top recommended items\n",
    "top_items = torch.argsort(scores, descending=True)\n",
    "\n",
    "# Display or return top recommended items\n",
    "print(\"Top recommended items for user:\", top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on  whole testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': 0, 'd2': 1, 'd3': 2}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['domain_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d1': <torch.utils.data.dataloader.DataLoader at 0x23f47975d00>,\n",
       " 'd2': <torch.utils.data.dataloader.DataLoader at 0x23fd0f93c20>,\n",
       " 'd3': <torch.utils.data.dataloader.DataLoader at 0x23f35d53ce0>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "{'HT_10': 0.14456346573134896, 'NDCG_10': 0.07255207233380863, 'F_10': 0.027287686039604377}\n"
     ]
    }
   ],
   "source": [
    "metrics_00=model.predict_full_rank(opt['domain_id']['d1'], test_dataloader['d1'], all_domain_set[opt['domain_id']['d1']], task_gen_all[opt['domain_id']['d1']].eval_set)\n",
    "print(metrics_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "{'HT_10': 0.5175624742659868, 'NDCG_10': 0.2843181192016272, 'F_10': 0.09608248518453952}\n"
     ]
    }
   ],
   "source": [
    "metrics_11=model.predict_full_rank(opt['domain_id']['d2'], test_dataloader['d2'], all_domain_set[opt['domain_id']['d2']], task_gen_all[opt['domain_id']['d2']].eval_set)\n",
    "\n",
    "print(metrics_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "{'HT_10': 0.662900679866264, 'NDCG_10': 0.34982383574615095, 'F_10': 0.12316479269315736}\n"
     ]
    }
   ],
   "source": [
    "metrics_11=model.predict_full_rank(opt['domain_id']['d3'], test_dataloader['d3'], all_domain_set[opt['domain_id']['d3']], task_gen_all[opt['domain_id']['d3']].eval_set)\n",
    "\n",
    "print(metrics_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset | Metric   | Paper Results | Our Results |\n",
    "|---------|----------|---------------|------------|\n",
    "| D1      | HT@10    | 32.60         | 14.46     |\n",
    "|         | NDCG@10  | 13.56         | 07.26     |\n",
    "| D2      | HT@10    | 64.37         | 51.76     |\n",
    "|         | NDCG@10  | 50.48         | 28.43     |\n",
    "| D3      | HT@10    | 73.89         | 66.29     |\n",
    "|         | NDCG@10  | 59.15         | 34.98     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
