{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils.GraphMaker import GraphMaker\n",
    "from model.trainer import CrossTrainer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import pdb\n",
    "import time\n",
    "import copy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'utils')\n",
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--static_sample --cuda --domains sport_cloth --aggregator user_attention  > dual_user_intra_sport_cloth.log 2>&1&"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--static_sample --cuda --domains game_video --task dual-user-inter --aggregator mean > dual_item_inter_game_video.log 2>&1&"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arg_parser():\n",
    "    \"\"\"Create argument parser for our baseline. \"\"\"\n",
    "    parser = argparse.ArgumentParser('WSDM')\n",
    "\n",
    "    # DATA  Arguments\n",
    "    parser.add_argument('--domains', type=str, default='d1_d2_d3', help='specify none (\"none\") or a few source markets (\"-\" seperated) to augment the data for training')\n",
    "    parser.add_argument('--task', type=str, default='multi-user-intra', help='dual-user-intra, dual-user-inter, multi-item-intra, multi-user-intra')\n",
    "\n",
    "    # MODEL Arguments\n",
    "    parser.add_argument('--model', type=str, default='UniCDR', help='right model name')\n",
    "    parser.add_argument('--mask_rate', type=float, default=0.1, help='mask rate of interactions')\n",
    "    parser.add_argument('--num_epoch', type=int, default=100, help='number of epoches')\n",
    "    parser.add_argument('--aggregator', type=str, default='mean', help='switching the user-item aggregation')\n",
    "    parser.add_argument('--batch_size', type=int, default=1024, help='batch size')\n",
    "    parser.add_argument('--optim', choices=['sgd', 'adagrad', 'adam', 'adamax'], default='adam',\n",
    "                        help='Optimizer: sgd, adagrad, adam or adamax.')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "    parser.add_argument('--l2_reg', type=float, default=1e-7, help='the L2 weight')\n",
    "    parser.add_argument('--lr_decay', type=float, default=0.98, help='decay learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-5, help='decay learning rate')\n",
    "    parser.add_argument('--latent_dim', type=int, default=128, help='latent dimensions')\n",
    "    parser.add_argument('--num_negative', type=int, default=10, help='num of negative samples during training')\n",
    "    parser.add_argument('--maxlen', type=int, default=10, help='num of item sequence')\n",
    "    parser.add_argument('--dropout', type=float, default=0.3, help='random drop out rate')\n",
    "    parser.add_argument('--save',default='save', action='store_true', help='save model?')\n",
    "    parser.add_argument('--lambda', type=float, default=50, help='the parameter of EASE')\n",
    "    parser.add_argument('--lambda_a', type=float, default=0.5, help='for our aggregators')\n",
    "    parser.add_argument('--lambda_loss', type=float, default=0.4, help='the parameter of loss function')\n",
    "    parser.add_argument('--static_sample', default='static_sample',action='store_true', help='accelerate the dataloader')\n",
    "\n",
    "    # others\n",
    "    parser.add_argument('--cuda',default='cuda', action='store_true', help='use of cuda')\n",
    "    parser.add_argument('--seed', type=int, default=42, help='manual seed init')\n",
    "    parser.add_argument('--decay_epoch', type=int, default=10, help='Decay learning rate after this epoch.')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = create_arg_parser()\n",
    "opt, _ = parser.parse_known_args()  # Ignore unknown arguments\n",
    "opt = vars(opt)\n",
    "\n",
    "opt[\"device\"] = torch.device('cuda' if torch.cuda.is_available() and opt[\"cuda\"] else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running with the following configs:\n",
      "\tdomains : d1_d2_d3\n",
      "\ttask : multi-user-intra\n",
      "\tmodel : UniCDR\n",
      "\tmask_rate : 0.1\n",
      "\tnum_epoch : 100\n",
      "\taggregator : mean\n",
      "\tbatch_size : 1024\n",
      "\toptim : adam\n",
      "\tlr : 0.001\n",
      "\tl2_reg : 1e-07\n",
      "\tlr_decay : 0.98\n",
      "\tweight_decay : 1e-05\n",
      "\tlatent_dim : 128\n",
      "\tnum_negative : 10\n",
      "\tmaxlen : 50\n",
      "\tdropout : 0.3\n",
      "\tsave : save\n",
      "\tlambda : 50\n",
      "\tlambda_a : 0.5\n",
      "\tlambda_loss : 0.4\n",
      "\tstatic_sample : static_sample\n",
      "\tcuda : cuda\n",
      "\tseed : 42\n",
      "\tdecay_epoch : 10\n",
      "\tdevice : cuda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_config(config):\n",
    "        info = \"Running with the following configs:\\n\"\n",
    "        for k, v in config.items():\n",
    "            info += \"\\t{} : {}\\n\".format(k, str(v))\n",
    "        print(\"\\n\" + info + \"\\n\")\n",
    "\n",
    "if opt[\"task\"] == \"multi-user-intra\":\n",
    "        opt[\"maxlen\"] = 50\n",
    "\n",
    "print_config(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'Running experiment on device: {opt[\"device\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1111):\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(opt[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d1_d2_d3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[\"domains\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading domains: ['d1', 'd2', 'd3']\n"
     ]
    }
   ],
   "source": [
    "if \"dual\" in opt[\"task\"]:\n",
    "        filename = opt[\"domains\"].split(\"_\")\n",
    "        opt[\"domains\"] = []\n",
    "        opt[\"domains\"].append(filename[0] + \"_\" + filename[1])\n",
    "        opt[\"domains\"].append(filename[1] + \"_\" + filename[0])\n",
    "        # filename = opt[\"domains\"].replace(' || ', '_').split('_')\n",
    "        # opt[\"domains\"] = []\n",
    "        # opt[\"domains\"].append(filename[0] + \"_\" + filename[1])\n",
    "        # opt[\"domains\"].append(filename[1] + \"_\" + filename[0])\n",
    "\n",
    "\n",
    "else:\n",
    "        opt[\"domains\"] = opt[\"domains\"].split('_')\n",
    "\n",
    "print(\"Loading domains:\", opt[\"domains\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = opt[\"domains\"]\n",
    "opt[\"user_max\"] = []\n",
    "opt[\"item_max\"] = []\n",
    "task_gen_all = {}\n",
    "domain_id = {}\n",
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading d1: datasets/multi-user-intra/dataset/d1/train.txt\n",
      "datasets/multi-user-intra/dataset/d1/train.txt\n",
      "d1\n",
      "['d1', 'd2', 'd3']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading d2: datasets/multi-user-intra/dataset/d2/train.txt\n",
      "datasets/multi-user-intra/dataset/d2/train.txt\n",
      "d2\n",
      "['d1', 'd2', 'd3']\n",
      "Loading d3: datasets/multi-user-intra/dataset/d3/train.txt\n",
      "datasets/multi-user-intra/dataset/d3/train.txt\n",
      "d3\n",
      "['d1', 'd2', 'd3']\n",
      "begin graphmaker................\n",
      "The alignment id 0 0\n",
      "231444 2097\n",
      "The alignment id 0 2096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\utils\\GraphMaker.py:14: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n",
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\utils\\GraphMaker.py:27: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:643.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647482 596\n",
      "The alignment id 0 2691\n",
      "1104098 1313\n",
      "graphmaker done.........\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        \n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        max_user = 0\n",
    "        max_item = 0\n",
    "        print(cur_src_data_dir)\n",
    "        print(cur_domain)\n",
    "        print(opt[\"domains\"])\n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter+=1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                max_user = max(max_user, user)\n",
    "                max_item = max(max_item, item)\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    all_domain_list[idx][user].append(item)\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        opt[\"user_max\"].append(max_user + 1)\n",
    "        opt[\"item_max\"].append(max_item + 1)\n",
    "\n",
    "total_graphs = GraphMaker(opt, all_domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading d1: datasets/multi-user-intra/dataset/d1/train.txt\n",
      "Loading d1: datasets/multi-user-intra/dataset/d1/train.txt\n",
      "the min/max user/item number of  datasets/multi-user-intra/dataset/d1/train.txt\n",
      "user: 0 231443\n",
      "item: 1 2096\n",
      "Loading d2: datasets/multi-user-intra/dataset/d2/train.txt\n",
      "Loading d2: datasets/multi-user-intra/dataset/d2/train.txt\n",
      "the min/max user/item number of  datasets/multi-user-intra/dataset/d2/train.txt\n",
      "user: 4 647481\n",
      "item: 1 595\n",
      "Loading d3: datasets/multi-user-intra/dataset/d3/train.txt\n",
      "Loading d3: datasets/multi-user-intra/dataset/d3/train.txt\n",
      "the min/max user/item number of  datasets/multi-user-intra/dataset/d3/train.txt\n",
      "user: 4 1104097\n",
      "item: 1 1312\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "\n",
    "        if opt[\"aggregator\"] == \"item_similarity\":\n",
    "            ease_dense = total_graphs.ease[idx].to_dense()\n",
    "\n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        \n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter += 1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    if opt[\"aggregator\"] == \"item_similarity\":\n",
    "                        all_domain_list[idx][user].append([item, ease_dense[user][item]])\n",
    "                    else:\n",
    "                        all_domain_list[idx][user].append([item, 1])\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        cur_src_task_generator = TaskGenerator(cur_src_data_dir, opt, all_domain_list, all_domain_set, idx,\n",
    "                                               total_graphs)\n",
    "        task_gen_all[idx] = cur_src_task_generator\n",
    "        domain_id[cur_domain] = idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_domains = MetaDomain_Dataset(task_gen_all, num_negatives=opt[\"num_negative\"], meta_split='train')\n",
    "train_dataloader = MetaDomain_DataLoader(train_domains, sample_batch_size=opt[\"batch_size\"] // len(domain_list), shuffle=True)\n",
    "opt[\"num_domains\"] = train_dataloader.num_domains\n",
    "opt[\"domain_id\"] = domain_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the evaluation data:  datasets/multi-user-intra/dataset/d1/valid.txt\n",
      "datasets/multi-user-intra/dataset/d1/valid.txt valid user:  10548\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d1/test.txt\n",
      "datasets/multi-user-intra/dataset/d1/test.txt valid user:  10549\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d2/valid.txt\n",
      "datasets/multi-user-intra/dataset/d2/valid.txt valid user:  31572\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d2/test.txt\n",
      "datasets/multi-user-intra/dataset/d2/test.txt valid user:  31573\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d3/valid.txt\n",
      "datasets/multi-user-intra/dataset/d3/valid.txt valid user:  80457\n",
      "the evaluation data:  datasets/multi-user-intra/dataset/d3/test.txt\n",
      "datasets/multi-user-intra/dataset/d3/test.txt valid user:  80457\n",
      "the user number of different domains [231444, 647482, 1104098]\n",
      "the item number of different domains [2097, 596, 1313]\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## Validation and Test\n",
    "############\n",
    "if \"inter\" in opt[\"task\"]:\n",
    "    opt[\"shared_user\"] = 1e9\n",
    "valid_dataloader = {}\n",
    "test_dataloader = {}\n",
    "for cur_domain in domain_list:\n",
    "        if opt[\"task\"] == \"dual-user-intra\":\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        else:\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/valid.txt\")\n",
    "        domain_test = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        valid_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_valid, 100)\n",
    "        test_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_test, 100)\n",
    "\n",
    "print(\"the user number of different domains\", opt[\"user_max\"])\n",
    "print(\"the item number of different domains\", opt[\"item_max\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:32: SyntaxWarning: \"is\" with 'int' literal. Did you mean \"==\"?\n",
      "<>:32: SyntaxWarning: \"is\" with 'int' literal. Did you mean \"==\"?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per batch of an epoch: 500\n",
      "Epoch 0 starts !\n",
      "Average loss: 0.0 time:  0.0 (min) current lr:  0.001\n",
      "--------------------------------------------------------------------------------\n",
      "0 loss is:  0.0\n",
      "1 loss is:  0.0\n",
      "2 loss is:  0.0\n",
      "Make prediction:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4152\\1277338744.py:32: SyntaxWarning: \"is\" with 'int' literal. Did you mean \"==\"?\n",
      "  if iteration % 10 is 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "-------------------d1--------------------\n",
      "{'HT_10': 0.00540386803185438, 'NDCG_10': 0.0017868874094988897, 'MRR': 0, 'F_10': 0.0009617370774088366}\n",
      "d1  better results!\n",
      "model saved to model_d1d2d3_epoch_0.pt\n",
      "best model saved!\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "{'HT_10': 0.006066925774954972, 'NDCG_10': 0.002258864074976702, 'MRR': 0, 'F_10': 0.0010791628214219706}\n",
      "Test metrics saved to multi-user-intra_d1d2d3_test_metrics.csv\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "-------------------d2--------------------\n",
      "{'HT_10': 0.01732547827188648, 'NDCG_10': 0.007145808378529932, 'MRR': 0, 'F_10': 0.0031172625104058}\n",
      "d2  better results!\n",
      "model saved to model_d1d2d3_epoch_0.pt\n",
      "best model saved!\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "{'HT_10': 0.01618471478795173, 'NDCG_10': 0.006531132425548334, 'MRR': 0, 'F_10': 0.0029074248745990833}\n",
      "Test metrics saved to multi-user-intra_d1d2d3_test_metrics.csv\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "-------------------d3--------------------\n",
      "{'HT_10': 0.005617907702250892, 'NDCG_10': 0.0020869755134952685, 'MRR': 0, 'F_10': 0.0010042872300192987}\n",
      "d3  better results!\n",
      "model saved to model_d1d2d3_epoch_0.pt\n",
      "best model saved!\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "{'HT_10': 0.006065351678536361, 'NDCG_10': 0.0024079017344966493, 'MRR': 0, 'F_10': 0.001085151499399014}\n",
      "Test metrics saved to multi-user-intra_d1d2d3_test_metrics.csv\n",
      "valid time:   3.5034077048301695 (min)\n",
      "decay_switch:  0\n",
      "Epoch 1 starts !\n",
      "............................................"
     ]
    }
   ],
   "source": [
    "############\n",
    "## Model\n",
    "############\n",
    "mymodel = CrossTrainer(opt)\n",
    "opt[\"num_epoch\"] = 100\n",
    "\n",
    "############\n",
    "## Train\n",
    "############\n",
    "dev_score_history = []\n",
    "for i in range(opt[\"num_domains\"]):\n",
    "    dev_score_history.append([0])\n",
    "\n",
    "\n",
    "current_lr = opt['lr']\n",
    "iteration_num = 500\n",
    "\n",
    "print(\"per batch of an epoch:\", iteration_num)\n",
    "global_step = 0\n",
    "for epoch in range(0, opt[\"num_epoch\"] + 1):\n",
    "    start_time = time.time()\n",
    "    print('Epoch {} starts !'.format(epoch))\n",
    "    total_loss = [0]\n",
    "\n",
    "    loss_list = []\n",
    "    for i in range(opt[\"num_domains\"]):\n",
    "        loss_list.append([0])\n",
    "\n",
    "    for iteration in range(iteration_num):\n",
    "        if epoch == 0:\n",
    "            continue\n",
    "        if iteration % 10 is 0:\n",
    "            print(\".\", end=\"\")\n",
    "\n",
    "        mymodel.model.train()\n",
    "        mymodel.optimizer.zero_grad()\n",
    "        mymodel.model.item_embedding_select()\n",
    "        mymodel_loss = 0\n",
    "\n",
    "        for idx in range(opt[\"num_domains\"]):  # get one batch from each dataloader\n",
    "            global_step += 1\n",
    "\n",
    "            cur_train_dataloader = train_dataloader.get_iterator(idx)\n",
    "            try:\n",
    "                batch_data = next(cur_train_dataloader)\n",
    "            except:\n",
    "                new_train_iterator = iter(train_dataloader[idx])\n",
    "                batch_data = next(new_train_iterator)\n",
    "\n",
    "            cur_loss = mymodel.reconstruct_graph(idx, batch_data)\n",
    "\n",
    "            mymodel_loss += cur_loss\n",
    "            loss_list[idx].append(cur_loss.item())\n",
    "            total_loss.append(cur_loss.item())\n",
    "\n",
    "\n",
    "        mymodel_loss.backward()\n",
    "        mymodel.optimizer.step()\n",
    "\n",
    "    print(\"Average loss:\", sum(total_loss)/len(total_loss), \"time: \", (time.time() - start_time) / 60, \"(min) current lr: \",\n",
    "            current_lr)\n",
    "\n",
    "    print('-' * 80)\n",
    "\n",
    "    if epoch % 5:\n",
    "        continue\n",
    "\n",
    "    for idx in range(opt[\"num_domains\"]):\n",
    "        print(idx, \"loss is: \", sum(loss_list[idx])/len(loss_list[idx]))\n",
    "\n",
    "    print('Make prediction:')\n",
    "    # validation data prediction\n",
    "    valid_start = time.time()\n",
    "\n",
    "    mymodel.model.eval()\n",
    "    mymodel.model.item_embedding_select()\n",
    "\n",
    "    decay_switch = 0\n",
    "    for idx, cur_domain in enumerate(valid_dataloader):\n",
    "        if opt[\"task\"] == \"multi-user-intra\":\n",
    "            metrics = mymodel.predict_full_rank(idx, valid_dataloader[cur_domain], all_domain_set[idx], task_gen_all[idx].eval_set)\n",
    "        else:\n",
    "            metrics = mymodel.predict(idx, valid_dataloader[cur_domain])\n",
    "\n",
    "        print(\"\\n-------------------\" + cur_domain + \"--------------------\")\n",
    "        print(metrics)\n",
    "\n",
    "\n",
    "        if metrics[\"NDCG_10\"] > max(dev_score_history[idx]):\n",
    "            # test data prediction\n",
    "            print(cur_domain, \" better results!\")\n",
    "\n",
    "            if opt[\"save\"]:\n",
    "                task = str(''.join(opt['domains'])) # Change this part accordding to one of the four datasets.\n",
    "                model_save_path = f'model_{task}_epoch_{epoch}.pt'  # Example filename: Added by Us\n",
    "                mymodel.save(model_save_path)\n",
    "                print(\"best model saved!\")\n",
    "\n",
    "            if opt[\"task\"] == \"multi-user-intra\":\n",
    "                test_metrics = mymodel.predict_full_rank(idx, test_dataloader[cur_domain], all_domain_set[idx], task_gen_all[idx].eval_set)\n",
    "            else:\n",
    "                test_metrics = mymodel.predict(idx, test_dataloader[cur_domain])\n",
    "\n",
    "            print(test_metrics)\n",
    "            ###############################################\n",
    "            # Saving the test metrics into a CSV file\n",
    "            \n",
    "            csv_filename = str(opt['task']) + \"_\" + str(''.join(opt['domains']))+\"_test_metrics.csv\"\n",
    "\n",
    "            # Add the epoch number to the test_metrics dictionary\n",
    "            test_metrics[\"epoch\"] = epoch  # Add the current epoch number to the metrics\n",
    "\n",
    "            # Update the columns to include 'epoch' as the first column\n",
    "            csv_columns = ['epoch'] + list(test_metrics.keys())  # 'epoch' first, then the rest of the metric keys\n",
    "\n",
    "            try:\n",
    "                # Check if the file exists. If not, create it with headers\n",
    "                with open(csv_filename, mode='a', newline='') as file:\n",
    "                    writer = csv.DictWriter(file, fieldnames=csv_columns)\n",
    "\n",
    "                    # Write the header only if the file is empty (appends without header otherwise)\n",
    "                    if file.tell() == 0:\n",
    "                        writer.writeheader()\n",
    "\n",
    "                    # Write the test_metrics as a new row\n",
    "                    writer.writerow(test_metrics)\n",
    "\n",
    "                print(f\"Test metrics saved to {csv_filename}\")\n",
    "            except IOError:\n",
    "                print(\"I/O error while saving test metrics\")\n",
    "        else:\n",
    "            decay_switch += 1\n",
    "        dev_score_history[idx].append(metrics[\"NDCG_10\"])\n",
    "\n",
    "    print(\"valid time:  \", (time.time() - valid_start) / 60, \"(min)\")\n",
    "\n",
    "\n",
    "    if epoch > opt['decay_epoch']:\n",
    "        mymodel.model.warmup = 0\n",
    "\n",
    "    # lr schedule\n",
    "    print(\"decay_switch: \", decay_switch)\n",
    "    if (epoch > opt['decay_epoch']) and (decay_switch > opt[\"num_domains\"] // 2) and (opt[\n",
    "        'optim'] in ['sgd', 'adagrad', 'adadelta', 'adam']):\n",
    "        current_lr *= opt['lr_decay']\n",
    "        mymodel.update_lr(current_lr)\n",
    "\n",
    "print('Experiment finished successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
