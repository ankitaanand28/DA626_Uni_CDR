{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils.GraphMaker import GraphMaker\n",
    "from model.trainer import CrossTrainer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import pdb\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'utils')\n",
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arg_parser():\n",
    "    \"\"\"Create argument parser for our baseline. \"\"\"\n",
    "    parser = argparse.ArgumentParser('WSDM')\n",
    "\n",
    "    # DATA  Arguments\n",
    "    parser.add_argument('--domains', type=str, default='m1_m2_m3_m4_m5', help='specify none (\"none\") or a few source markets (\"-\" seperated) to augment the data for training')\n",
    "    parser.add_argument('--task', type=str, default='multi-item-intra', help='dual-user-intra, dual-user-inter, multi-item-intra, multi-user-intra')\n",
    "\n",
    "    # MODEL Arguments\n",
    "    parser.add_argument('--model', type=str, default='UniCDR', help='right model name')\n",
    "    parser.add_argument('--mask_rate', type=float, default=0.1, help='mask rate of interactions')\n",
    "    parser.add_argument('--num_epoch', type=int, default=100, help='number of epoches')\n",
    "    parser.add_argument('--aggregator', type=str, default='item_similarity', help='switching the user-item aggregation')\n",
    "    parser.add_argument('--batch_size', type=int, default=1024, help='batch size')\n",
    "    parser.add_argument('--optim', choices=['sgd', 'adagrad', 'adam', 'adamax'], default='adam',\n",
    "                        help='Optimizer: sgd, adagrad, adam or adamax.')\n",
    "    parser.add_argument('--lr', type=float, default=0.005, help='learning rate')\n",
    "    parser.add_argument('--l2_reg', type=float, default=1e-6, help='the L2 weight')\n",
    "    parser.add_argument('--lr_decay', type=float, default=0.98, help='decay learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-5, help='decay learning rate')\n",
    "    parser.add_argument('--latent_dim', type=int, default=128, help='latent dimensions')\n",
    "    parser.add_argument('--num_negative', type=int, default=10, help='num of negative samples during training')\n",
    "    parser.add_argument('--maxlen', type=int, default=10, help='num of item sequence')\n",
    "    parser.add_argument('--dropout', type=float, default=0.3, help='random drop out rate')\n",
    "    parser.add_argument('--save',default='save', action='store_true', help='save model?')\n",
    "    parser.add_argument('--lambda', type=float, default=50, help='the parameter of EASE')\n",
    "    parser.add_argument('--lambda_a', type=float, default=0.5, help='for our aggregators')\n",
    "    parser.add_argument('--lambda_loss', type=float, default=0.4, help='the parameter of loss function')\n",
    "    parser.add_argument('--static_sample', default='static_sample',action='store_true', help='accelerate the dataloader')\n",
    "\n",
    "    # others\n",
    "    parser.add_argument('--cuda',default='cuda', action='store_true', help='use of cuda')\n",
    "    parser.add_argument('--seed', type=int, default=42, help='manual seed init')\n",
    "    parser.add_argument('--decay_epoch', type=int, default=10, help='Decay learning rate after this epoch.')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = create_arg_parser()\n",
    "opt, _ = parser.parse_known_args()  # Ignore unknown arguments\n",
    "opt = vars(opt)\n",
    "\n",
    "opt[\"device\"] = torch.device('cuda' if torch.cuda.is_available() and opt[\"cuda\"] else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running with the following configs:\n",
      "\tdomains : m1_m2_m3_m4_m5\n",
      "\ttask : multi-item-intra\n",
      "\tmodel : UniCDR\n",
      "\tmask_rate : 0.1\n",
      "\tnum_epoch : 100\n",
      "\taggregator : item_similarity\n",
      "\tbatch_size : 1024\n",
      "\toptim : adam\n",
      "\tlr : 0.005\n",
      "\tl2_reg : 1e-06\n",
      "\tlr_decay : 0.98\n",
      "\tweight_decay : 1e-05\n",
      "\tlatent_dim : 128\n",
      "\tnum_negative : 10\n",
      "\tmaxlen : 10\n",
      "\tdropout : 0.3\n",
      "\tsave : save\n",
      "\tlambda : 50\n",
      "\tlambda_a : 0.5\n",
      "\tlambda_loss : 0.4\n",
      "\tstatic_sample : static_sample\n",
      "\tcuda : cuda\n",
      "\tseed : 42\n",
      "\tdecay_epoch : 10\n",
      "\tdevice : cuda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_config(config):\n",
    "        info = \"Running with the following configs:\\n\"\n",
    "        for k, v in config.items():\n",
    "            info += \"\\t{} : {}\\n\".format(k, str(v))\n",
    "        print(\"\\n\" + info + \"\\n\")\n",
    "\n",
    "if opt[\"task\"] == \"multi-user-intra\":\n",
    "        opt[\"maxlen\"] = 50\n",
    "\n",
    "print_config(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'Running experiment on device: {opt[\"device\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1111):\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(opt[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m1_m2_m3_m4_m5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[\"domains\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading domains: ['m1', 'm2', 'm3', 'm4', 'm5']\n"
     ]
    }
   ],
   "source": [
    "if \"dual\" in opt[\"task\"]:\n",
    "        filename = opt[\"domains\"].split(\"_\")\n",
    "        opt[\"domains\"] = []\n",
    "        opt[\"domains\"].append(filename[0] + \"_\" + filename[1])\n",
    "        opt[\"domains\"].append(filename[1] + \"_\" + filename[0])\n",
    "\n",
    "\n",
    "else:\n",
    "        opt[\"domains\"] = opt[\"domains\"].split('_')\n",
    "\n",
    "print(\"Loading domains:\", opt[\"domains\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = opt[\"domains\"]\n",
    "opt[\"user_max\"] = []\n",
    "opt[\"item_max\"] = []\n",
    "task_gen_all = {}\n",
    "domain_id = {}\n",
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading m1: datasets/multi-item-intra/dataset/m1/train.txt\n",
      "datasets/multi-item-intra/dataset/m1/train.txt\n",
      "m1\n",
      "['m1', 'm2', 'm3', 'm4', 'm5']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading m2: datasets/multi-item-intra/dataset/m2/train.txt\n",
      "datasets/multi-item-intra/dataset/m2/train.txt\n",
      "m2\n",
      "['m1', 'm2', 'm3', 'm4', 'm5']\n",
      "Loading m3: datasets/multi-item-intra/dataset/m3/train.txt\n",
      "datasets/multi-item-intra/dataset/m3/train.txt\n",
      "m3\n",
      "['m1', 'm2', 'm3', 'm4', 'm5']\n",
      "Loading m4: datasets/multi-item-intra/dataset/m4/train.txt\n",
      "datasets/multi-item-intra/dataset/m4/train.txt\n",
      "m4\n",
      "['m1', 'm2', 'm3', 'm4', 'm5']\n",
      "Loading m5: datasets/multi-item-intra/dataset/m5/train.txt\n",
      "datasets/multi-item-intra/dataset/m5/train.txt\n",
      "m5\n",
      "['m1', 'm2', 'm3', 'm4', 'm5']\n",
      "begin graphmaker................\n",
      "The alignment id 0 0\n",
      "7109 2199\n",
      "Start the EASE\n",
      "load\n",
      "15625582\n",
      "49169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\utils\\GraphMaker.py:14: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n",
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\utils\\GraphMaker.py:27: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:643.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EASE End\n",
      "The alignment id 7109 0\n",
      "2697 2693\n",
      "Start the EASE\n",
      "load\n",
      "3592711\n",
      "17953\n",
      "EASE End\n",
      "The alignment id 9806 0\n",
      "3328 2979\n",
      "Start the EASE\n",
      "load\n",
      "4143360\n",
      "23363\n",
      "EASE End\n",
      "The alignment id 13134 0\n",
      "5482 4931\n",
      "Start the EASE\n",
      "load\n",
      "15990994\n",
      "31907\n",
      "EASE End\n",
      "The alignment id 18616 0\n",
      "6466 12016\n",
      "Start the EASE\n",
      "load\n",
      "63121092\n",
      "77136\n",
      "EASE End\n",
      "graphmaker done.........\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        \n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        max_user = 0\n",
    "        max_item = 0\n",
    "        print(cur_src_data_dir)\n",
    "        print(cur_domain)\n",
    "        print(opt[\"domains\"])\n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter+=1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                max_user = max(max_user, user)\n",
    "                max_item = max(max_item, item)\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    all_domain_list[idx][user].append(item)\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        opt[\"user_max\"].append(max_user + 1)\n",
    "        opt[\"item_max\"].append(max_item + 1)\n",
    "\n",
    "total_graphs = GraphMaker(opt, all_domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading m1: datasets/multi-item-intra/dataset/m1/train.txt\n",
      "Loading m1: datasets/multi-item-intra/dataset/m1/train.txt\n",
      "the min/max user/item number of  datasets/multi-item-intra/dataset/m1/train.txt\n",
      "user: 0 7108\n",
      "item: 1 2198\n",
      "Loading m2: datasets/multi-item-intra/dataset/m2/train.txt\n",
      "Loading m2: datasets/multi-item-intra/dataset/m2/train.txt\n",
      "the min/max user/item number of  datasets/multi-item-intra/dataset/m2/train.txt\n",
      "user: 0 2696\n",
      "item: 1 2692\n",
      "Loading m3: datasets/multi-item-intra/dataset/m3/train.txt\n",
      "Loading m3: datasets/multi-item-intra/dataset/m3/train.txt\n",
      "the min/max user/item number of  datasets/multi-item-intra/dataset/m3/train.txt\n",
      "user: 0 3327\n",
      "item: 1 2978\n",
      "Loading m4: datasets/multi-item-intra/dataset/m4/train.txt\n",
      "Loading m4: datasets/multi-item-intra/dataset/m4/train.txt\n",
      "the min/max user/item number of  datasets/multi-item-intra/dataset/m4/train.txt\n",
      "user: 0 5481\n",
      "item: 2 4930\n",
      "Loading m5: datasets/multi-item-intra/dataset/m5/train.txt\n",
      "Loading m5: datasets/multi-item-intra/dataset/m5/train.txt\n",
      "the min/max user/item number of  datasets/multi-item-intra/dataset/m5/train.txt\n",
      "user: 0 6465\n",
      "item: 1 12015\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "\n",
    "        if opt[\"aggregator\"] == \"item_similarity\":\n",
    "            ease_dense = total_graphs.ease[idx].to_dense()\n",
    "\n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        \n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter += 1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    if opt[\"aggregator\"] == \"item_similarity\":\n",
    "                        all_domain_list[idx][user].append([item, ease_dense[user][item]])\n",
    "                    else:\n",
    "                        all_domain_list[idx][user].append([item, 1])\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        cur_src_task_generator = TaskGenerator(cur_src_data_dir, opt, all_domain_list, all_domain_set, idx,\n",
    "                                               total_graphs)\n",
    "        task_gen_all[idx] = cur_src_task_generator\n",
    "        domain_id[cur_domain] = idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_domains = MetaDomain_Dataset(task_gen_all, num_negatives=opt[\"num_negative\"], meta_split='train')\n",
    "train_dataloader = MetaDomain_DataLoader(train_domains, sample_batch_size=opt[\"batch_size\"] // len(domain_list), shuffle=True)\n",
    "opt[\"num_domains\"] = train_dataloader.num_domains\n",
    "opt[\"domain_id\"] = domain_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the evaluation data:  datasets/multi-item-intra/dataset/m1/valid.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m1/test.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m2/valid.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m2/test.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m3/valid.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m3/test.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m4/valid.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m4/test.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m5/valid.txt\n",
      "the evaluation data:  datasets/multi-item-intra/dataset/m5/test.txt\n",
      "the user number of different domains [7109, 2697, 3328, 5482, 6466]\n",
      "the item number of different domains [2199, 2693, 2979, 4931, 12016]\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## Validation and Test\n",
    "############\n",
    "if \"inter\" in opt[\"task\"]:\n",
    "    opt[\"shared_user\"] = 1e9\n",
    "valid_dataloader = {}\n",
    "test_dataloader = {}\n",
    "for cur_domain in domain_list:\n",
    "        if opt[\"task\"] == \"dual-user-intra\":\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        else:\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/valid.txt\")\n",
    "        domain_test = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        valid_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_valid, 100)\n",
    "        test_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_test, 100)\n",
    "\n",
    "print(\"the user number of different domains\", opt[\"user_max\"])\n",
    "print(\"the item number of different domains\", opt[\"item_max\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_10444\\3732012432.py:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  model_weights_path = 'Trained_Model\\model_m1m2m3m4m5_epoch_120.pt'\n",
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\model\\trainer.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.GraphMaker import GraphMaker\n",
    "from model.trainer import CrossTrainer\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Define paths to saved weights and dataset\n",
    "model_weights_path = 'Trained_Model\\model_m1m2m3m4m5_epoch_120.pt'\n",
    "\n",
    "\n",
    "# Initialize model with the same architecture as training\n",
    "model = CrossTrainer(opt)  # `opt` should be the same dictionary used during training\n",
    "\n",
    "\n",
    "\n",
    "# Load the model using the custom `load()` method of CrossTrainer\n",
    "model.load(model_weights_path)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.model.eval()\n",
    "\n",
    "# Load and preprocess the dataset using GraphMaker\n",
    "graph_maker = total_graphs\n",
    "UV_adj, VU_adj, ease_pred = graph_maker.UV, graph_maker.VU, graph_maker.ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on particular example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of UV_adj: 5\n",
      "Length of VU_adj: 5\n",
      "Length of ease_pred: 5\n",
      "User index: tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define user index and item indices for inference\n",
    "user_idx = torch.tensor([1], dtype=torch.long).to(device)  # Move user index to the same device\n",
    "item_indices = torch.tensor([1, 2,4, 6], dtype=torch.long).to(device)  # Move item indices to the same device\n",
    "print(f\"Length of UV_adj: {len(UV_adj)}\")\n",
    "print(f\"Length of VU_adj: {len(VU_adj)}\")\n",
    "print(f\"Length of ease_pred: {len(ease_pred)}\")\n",
    "print(f\"User index: {user_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1': 0, 'm2': 1, 'm3': 2, 'm4': 3, 'm5': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['domain_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended items for user: tensor([2, 0, 1, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Ensure item embeddings are initialized (fix for con_item_emb_list)\n",
    "model.model.item_embedding_select()\n",
    "\n",
    "# Specify a domain to run inference on, here it's 'game_video' and 'video_game'\n",
    "domain_id = opt['domain_id']['m1']  # Change based on domain\n",
    "\n",
    "# Define user index and item indices for inference\n",
    "user_idx = torch.tensor([0], dtype=torch.long).to(device)  # Move user index to the same device\n",
    "item_indices = torch.tensor([1,2, 4, 6], dtype=torch.long).to(device)  # Move item indices to the same device\n",
    "\n",
    "# Ensure user_idx is valid\n",
    "if user_idx >= len(UV_adj) or user_idx >= len(VU_adj) or user_idx >= len(ease_pred):\n",
    "    raise ValueError(f\"user_idx {user_idx} is out of bounds for the dataset.\")\n",
    "# Define dummy context and global scores, and move them to the correct device\n",
    "context_item = torch.zeros((1, 10), dtype=torch.long).to(device)  # Adjust based on your model\n",
    "context_score = torch.zeros((1, 10), dtype=torch.float).to(device)  # Adjust based on your model\n",
    "global_item = torch.zeros((1, len(item_indices), len(item_indices)), dtype=torch.long).to(device)  # Adjust shape\n",
    "global_score = torch.zeros((1, len(item_indices)), dtype=torch.float).to(device)  # Adjust shape\n",
    "\n",
    "# Get user embeddings using the model\n",
    "user_embedding = model.model.forward_user(domain_id, user_idx, context_item, context_score, global_item, global_score)\n",
    "\n",
    "# Get item embeddings using the model\n",
    "item_embeddings = model.model.forward_item(domain_id, item_indices)\n",
    "\n",
    "# Use the predict_dot method to generate the predictions (dot product of user and item embeddings)\n",
    "scores = model.model.predict_dot(user_embedding, item_embeddings)\n",
    "\n",
    "# Sort the scores to get top recommended items\n",
    "top_items = torch.argsort(scores, descending=True)\n",
    "\n",
    "# Display or return top recommended items\n",
    "print(\"Top recommended items for user:\", top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on  whole testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1': 0, 'm2': 1, 'm3': 2, 'm4': 3, 'm5': 4}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['domain_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1': <torch.utils.data.dataloader.DataLoader at 0x29471a0abd0>,\n",
       " 'm2': <torch.utils.data.dataloader.DataLoader at 0x294425bf050>,\n",
       " 'm3': <torch.utils.data.dataloader.DataLoader at 0x29430c66ff0>,\n",
       " 'm4': <torch.utils.data.dataloader.DataLoader at 0x2947d214470>,\n",
       " 'm5': <torch.utils.data.dataloader.DataLoader at 0x29465b14b30>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++\n",
      "{'NDCG_10': 0.6085969339044249, 'HT_10': 0.6877459246767847}\n"
     ]
    }
   ],
   "source": [
    "metrics_00=model.predict(opt['domain_id']['m1'],test_dataloader['m1'])\n",
    "print(metrics_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++\n",
      "{'NDCG_10': 0.4789027750796816, 'HT_10': 0.5770992366412214}\n"
     ]
    }
   ],
   "source": [
    "metrics_11=model.predict(opt['domain_id']['m2'],test_dataloader['m2'])\n",
    "print(metrics_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++\n",
      "{'NDCG_10': 0.5262964111285614, 'HT_10': 0.6388557806912991}\n"
     ]
    }
   ],
   "source": [
    "metrics_22=model.predict(opt['domain_id']['m3'],test_dataloader['m3'])\n",
    "print(metrics_22) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++\n",
      "{'NDCG_10': 0.41693872967824097, 'HT_10': 0.46461312797946464}\n"
     ]
    }
   ],
   "source": [
    "metrics_33=model.predict(opt['domain_id']['m4'],test_dataloader['m4'])\n",
    "print(metrics_33 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++\n",
      "{'NDCG_10': 0.14830805677220618, 'HT_10': 0.18262523779327838}\n"
     ]
    }
   ],
   "source": [
    "metrics_44=model.predict(opt['domain_id']['m5'],test_dataloader['m5'])\n",
    "print(metrics_44 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Dataset** | **Metric** | **Paper Results** | **Our Results** |\n",
    "|-------------|------------|-------------------|-------------------------------------|\n",
    "| **M1**      | NDCG@10   | 55.83             | 60.86                               |\n",
    "|             | HT@10     | 69.08             | 68.77                               |\n",
    "| **M2**      | NDCG@10   | 40.04             | 47.89                               |\n",
    "|             | HT@10     | 58.01             | 57.71                               |\n",
    "| **M3**      | NDCG@10   | 43.35             | 52.63                               |\n",
    "|             | HT@10     | 64.60             | 63.89                               |\n",
    "| **M4**      | NDCG@10   | 42.54             | 41.69                               |\n",
    "|             | HT@10     | 47.52             | 46.46                               |\n",
    "| **M5**      | NDCG@10   | 17.04             | 14.83                               |\n",
    "|             | HT@10     | 19.78             | 18.26                               |\n",
    "\n",
    "**Table**: Comparison of multi-item intra recommendation results for M1, M2, M3, M4, and M5 datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
