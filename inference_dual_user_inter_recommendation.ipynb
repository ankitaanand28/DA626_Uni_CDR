{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from utils.GraphMaker import GraphMaker\n",
    "from model.trainer import CrossTrainer\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import pdb\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, 'utils')\n",
    "from utils.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arg_parser():\n",
    "    \"\"\"Create argument parser for our baseline. \"\"\"\n",
    "    parser = argparse.ArgumentParser('WSDM')\n",
    "\n",
    "    # DATA  Arguments\n",
    "    parser.add_argument('--domains', type=str, default='game_video', help='specify none (\"none\") or a few source markets (\"-\" seperated) to augment the data for training')\n",
    "    parser.add_argument('--task', type=str, default='dual-user-inter', help='dual-user-intra, dual-user-inter, multi-item-intra, multi-user-intra')\n",
    "\n",
    "    # MODEL Arguments\n",
    "    parser.add_argument('--model', type=str, default='UniCDR', help='right model name')\n",
    "    parser.add_argument('--mask_rate', type=float, default=0.1, help='mask rate of interactions')\n",
    "    parser.add_argument('--num_epoch', type=int, default=100, help='number of epoches')\n",
    "    parser.add_argument('--aggregator', type=str, default='mean', help='switching the user-item aggregation')\n",
    "    parser.add_argument('--batch_size', type=int, default=1024, help='batch size')\n",
    "    parser.add_argument('--optim', choices=['sgd', 'adagrad', 'adam', 'adamax'], default='adam',\n",
    "                        help='Optimizer: sgd, adagrad, adam or adamax.')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "    parser.add_argument('--l2_reg', type=float, default=1e-7, help='the L2 weight')\n",
    "    parser.add_argument('--lr_decay', type=float, default=0.98, help='decay learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-5, help='decay learning rate')\n",
    "    parser.add_argument('--latent_dim', type=int, default=128, help='latent dimensions')\n",
    "    parser.add_argument('--num_negative', type=int, default=10, help='num of negative samples during training')\n",
    "    parser.add_argument('--maxlen', type=int, default=10, help='num of item sequence')\n",
    "    parser.add_argument('--dropout', type=float, default=0.3, help='random drop out rate')\n",
    "    parser.add_argument('--save',default='save', action='store_true', help='save model?')\n",
    "    parser.add_argument('--lambda', type=float, default=50, help='the parameter of EASE')\n",
    "    parser.add_argument('--lambda_a', type=float, default=0.5, help='for our aggregators')\n",
    "    parser.add_argument('--lambda_loss', type=float, default=0.4, help='the parameter of loss function')\n",
    "    parser.add_argument('--static_sample', default='static_sample',action='store_true', help='accelerate the dataloader')\n",
    "\n",
    "    # others\n",
    "    parser.add_argument('--cuda',default='cuda', action='store_true', help='use of cuda')\n",
    "    parser.add_argument('--seed', type=int, default=42, help='manual seed init')\n",
    "    parser.add_argument('--decay_epoch', type=int, default=10, help='Decay learning rate after this epoch.')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = create_arg_parser()\n",
    "opt, _ = parser.parse_known_args()  # Ignore unknown arguments\n",
    "opt = vars(opt)\n",
    "\n",
    "opt[\"device\"] = torch.device('cuda' if torch.cuda.is_available() and opt[\"cuda\"] else 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running with the following configs:\n",
      "\tdomains : game_video\n",
      "\ttask : dual-user-inter\n",
      "\tmodel : UniCDR\n",
      "\tmask_rate : 0.1\n",
      "\tnum_epoch : 100\n",
      "\taggregator : mean\n",
      "\tbatch_size : 1024\n",
      "\toptim : adam\n",
      "\tlr : 0.001\n",
      "\tl2_reg : 1e-07\n",
      "\tlr_decay : 0.98\n",
      "\tweight_decay : 1e-05\n",
      "\tlatent_dim : 128\n",
      "\tnum_negative : 10\n",
      "\tmaxlen : 10\n",
      "\tdropout : 0.3\n",
      "\tsave : save\n",
      "\tlambda : 50\n",
      "\tlambda_a : 0.5\n",
      "\tlambda_loss : 0.4\n",
      "\tstatic_sample : static_sample\n",
      "\tcuda : cuda\n",
      "\tseed : 42\n",
      "\tdecay_epoch : 10\n",
      "\tdevice : cuda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_config(config):\n",
    "        info = \"Running with the following configs:\\n\"\n",
    "        for k, v in config.items():\n",
    "            info += \"\\t{} : {}\\n\".format(k, str(v))\n",
    "        print(\"\\n\" + info + \"\\n\")\n",
    "\n",
    "if opt[\"task\"] == \"multi-user-intra\":\n",
    "        opt[\"maxlen\"] = 50\n",
    "\n",
    "print_config(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment on device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'Running experiment on device: {opt[\"device\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1111):\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(opt[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game_video'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[\"domains\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading domains: ['game_video', 'video_game']\n"
     ]
    }
   ],
   "source": [
    "if \"dual\" in opt[\"task\"]:\n",
    "        filename = opt[\"domains\"].split(\"_\")\n",
    "        opt[\"domains\"] = []\n",
    "        opt[\"domains\"].append(filename[0] + \"_\" + filename[1])\n",
    "        opt[\"domains\"].append(filename[1] + \"_\" + filename[0])\n",
    "        \n",
    "\n",
    "\n",
    "else:\n",
    "        opt[\"domains\"] = opt[\"domains\"].split('_')\n",
    "\n",
    "print(\"Loading domains:\", opt[\"domains\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = opt[\"domains\"]\n",
    "opt[\"user_max\"] = []\n",
    "opt[\"item_max\"] = []\n",
    "task_gen_all = {}\n",
    "domain_id = {}\n",
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading game_video: datasets/dual-user-inter/dataset/game_video/train.txt\n",
      "datasets/dual-user-inter/dataset/game_video/train.txt\n",
      "game_video\n",
      "['game_video', 'video_game']\n",
      "Loading video_game: datasets/dual-user-inter/dataset/video_game/train.txt\n",
      "datasets/dual-user-inter/dataset/video_game/train.txt\n",
      "video_game\n",
      "['game_video', 'video_game']\n",
      "begin graphmaker................\n",
      "The alignment id 0 0\n",
      "25025 12320\n",
      "The alignment id 0 12319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\utils\\GraphMaker.py:14: RuntimeWarning: divide by zero encountered in power\n",
      "  r_inv = np.power(rowsum, -1).flatten()\n",
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\utils\\GraphMaker.py:27: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:643.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19457 8752\n",
      "graphmaker done.........\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        \n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        max_user = 0\n",
    "        max_item = 0\n",
    "        print(cur_src_data_dir)\n",
    "        print(cur_domain)\n",
    "        print(opt[\"domains\"])\n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter+=1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                max_user = max(max_user, user)\n",
    "                max_item = max(max_item, item)\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    all_domain_list[idx][user].append(item)\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        opt[\"user_max\"].append(max_user + 1)\n",
    "        opt[\"item_max\"].append(max_item + 1)\n",
    "\n",
    "total_graphs = GraphMaker(opt, all_domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domain_list = []\n",
    "all_domain_set = []\n",
    "all_inter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading game_video: datasets/dual-user-inter/dataset/game_video/train.txt\n",
      "Loading game_video: datasets/dual-user-inter/dataset/game_video/train.txt\n",
      "the min/max user/item number of  datasets/dual-user-inter/dataset/game_video/train.txt\n",
      "user: 0 25024\n",
      "item: 1 12319\n",
      "Loading video_game: datasets/dual-user-inter/dataset/video_game/train.txt\n",
      "Loading video_game: datasets/dual-user-inter/dataset/video_game/train.txt\n",
      "the min/max user/item number of  datasets/dual-user-inter/dataset/video_game/train.txt\n",
      "user: 0 19456\n",
      "item: 1 8751\n"
     ]
    }
   ],
   "source": [
    "for idx, cur_domain in enumerate(domain_list):\n",
    "        cur_src_data_dir = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/train.txt\")\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "\n",
    "        if opt[\"aggregator\"] == \"item_similarity\":\n",
    "            ease_dense = total_graphs.ease[idx].to_dense()\n",
    "\n",
    "        all_domain_list.append({})\n",
    "        all_domain_set.append({})\n",
    "        \n",
    "        with codecs.open(cur_src_data_dir, \"r\", encoding=\"utf-8\") as infile:\n",
    "            for line in infile:\n",
    "                all_inter += 1\n",
    "                line = line.strip().split(\"\\t\")\n",
    "                user = int(line[0])\n",
    "                item = int(line[1]) + 1\n",
    "                if user not in all_domain_list[idx].keys():\n",
    "                    all_domain_list[idx][user] = []\n",
    "                    all_domain_set[idx][user] = set()\n",
    "                if item not in all_domain_set[idx][user]:\n",
    "                    if opt[\"aggregator\"] == \"item_similarity\":\n",
    "                        all_domain_list[idx][user].append([item, ease_dense[user][item]])\n",
    "                    else:\n",
    "                        all_domain_list[idx][user].append([item, 1])\n",
    "                    all_domain_set[idx][user].add(item)\n",
    "\n",
    "        print(f'Loading {cur_domain}: {cur_src_data_dir}')\n",
    "        cur_src_task_generator = TaskGenerator(cur_src_data_dir, opt, all_domain_list, all_domain_set, idx,\n",
    "                                               total_graphs)\n",
    "        task_gen_all[idx] = cur_src_task_generator\n",
    "        domain_id[cur_domain] = idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_domains = MetaDomain_Dataset(task_gen_all, num_negatives=opt[\"num_negative\"], meta_split='train')\n",
    "train_dataloader = MetaDomain_DataLoader(train_domains, sample_batch_size=opt[\"batch_size\"] // len(domain_list), shuffle=True)\n",
    "opt[\"num_domains\"] = train_dataloader.num_domains\n",
    "opt[\"domain_id\"] = domain_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the evaluation data:  datasets/dual-user-inter/dataset/game_video/valid.txt\n",
      "the evaluation data:  datasets/dual-user-inter/dataset/game_video/test.txt\n",
      "the evaluation data:  datasets/dual-user-inter/dataset/video_game/valid.txt\n",
      "the evaluation data:  datasets/dual-user-inter/dataset/video_game/test.txt\n",
      "the user number of different domains [25025, 19457]\n",
      "the item number of different domains [12320, 8752]\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "## Validation and Test\n",
    "############\n",
    "if \"inter\" in opt[\"task\"]:\n",
    "    opt[\"shared_user\"] = 1e9\n",
    "valid_dataloader = {}\n",
    "test_dataloader = {}\n",
    "for cur_domain in domain_list:\n",
    "        if opt[\"task\"] == \"dual-user-intra\":\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        else:\n",
    "            domain_valid = os.path.join(\"datasets/\" + str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/valid.txt\")\n",
    "        domain_test = os.path.join(\"datasets/\"+str(opt[\"task\"]) + \"/dataset/\", cur_domain + \"/test.txt\")\n",
    "        valid_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_valid, 100)\n",
    "        test_dataloader[cur_domain] = task_gen_all[domain_id[cur_domain]].instance_a_valid_dataloader(\n",
    "            domain_test, 100)\n",
    "\n",
    "print(\"the user number of different domains\", opt[\"user_max\"])\n",
    "print(\"the item number of different domains\", opt[\"item_max\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15440\\2436894746.py:7: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  model_weights_path = 'Trained_Model\\model_ dual_item_inter_game_video_epoch_100.pt'\n",
      "c:\\Users\\HP\\Desktop\\OE Project\\UniCDR-main\\UniCDR\\model\\trainer.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.GraphMaker import GraphMaker\n",
    "from model.trainer import CrossTrainer\n",
    "import os\n",
    "\n",
    "# Define paths to saved weights and dataset\n",
    "model_weights_path = 'Trained_Model\\model_ dual_item_inter_game_video_epoch_100.pt'\n",
    "\n",
    "\n",
    "# Initialize model with the same architecture as training\n",
    "model = CrossTrainer(opt)  # `opt` should be the same dictionary used during training\n",
    "\n",
    "\n",
    "\n",
    "# Load the model using the custom `load()` method of CrossTrainer\n",
    "model.load(model_weights_path)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.model.eval()\n",
    "\n",
    "# Load and preprocess the dataset using GraphMaker\n",
    "graph_maker = total_graphs\n",
    "UV_adj, VU_adj, ease_pred = graph_maker.UV, graph_maker.VU, graph_maker.ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on particular example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of UV_adj: 2\n",
      "Length of VU_adj: 2\n",
      "Length of ease_pred: 2\n",
      "User index: tensor([1, 2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define user index and item indices for inference\n",
    "user_idx = torch.tensor([1,2], dtype=torch.long).to(device)  # Move user index to the same device\n",
    "item_indices = torch.tensor([1, 5,8,4, 6], dtype=torch.long).to(device)  # Move item indices to the same device\n",
    "print(f\"Length of UV_adj: {len(UV_adj)}\")\n",
    "print(f\"Length of VU_adj: {len(VU_adj)}\")\n",
    "print(f\"Length of ease_pred: {len(ease_pred)}\")\n",
    "print(f\"User index: {user_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended items for user: tensor([3, 2, 0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Ensure item embeddings are initialized (fix for con_item_emb_list)\n",
    "model.model.item_embedding_select()\n",
    "\n",
    "# Specify a domain to run inference on, here it's 'game_video' and 'video_game'\n",
    "domain_id_1 = opt['domain_id']['game_video']  # Change based on domain\n",
    "domain_id_2 = opt['domain_id']['video_game'] \n",
    "# Define user index and item indices for inference\n",
    "user_idx = torch.tensor([0], dtype=torch.long).to(device)  # Move user index to the same device\n",
    "item_indices = torch.tensor([1,2, 4, 6], dtype=torch.long).to(device)  # Move item indices to the same device\n",
    "\n",
    "# Ensure user_idx is valid\n",
    "if user_idx >= len(UV_adj) or user_idx >= len(VU_adj) or user_idx >= len(ease_pred):\n",
    "    raise ValueError(f\"user_idx {user_idx} is out of bounds for the dataset.\")\n",
    "# Define dummy context and global scores, and move them to the correct device\n",
    "context_item = torch.zeros((1, 10), dtype=torch.long).to(device)  # Adjust based on your model\n",
    "context_score = torch.zeros((1, 10), dtype=torch.float).to(device)  # Adjust based on your model\n",
    "global_item = torch.zeros((1, len(item_indices), len(item_indices)), dtype=torch.long).to(device)  # Adjust shape\n",
    "global_score = torch.zeros((1, len(item_indices)), dtype=torch.float).to(device)  # Adjust shape\n",
    "\n",
    "# Get user embeddings using the model\n",
    "user_embedding = model.model.forward_user(domain_id_1, user_idx, context_item, context_score, global_item, global_score)\n",
    "\n",
    "# Get item embeddings using the model\n",
    "item_embeddings = model.model.forward_item(domain_id_2, item_indices)\n",
    "\n",
    "# Use the predict_dot method to generate the predictions (dot product of user and item embeddings)\n",
    "scores = model.model.predict_dot(user_embedding, item_embeddings)\n",
    "\n",
    "# Sort the scores to get top recommended items\n",
    "top_items = torch.argsort(scores, descending=True)\n",
    "\n",
    "# Display or return top recommended items\n",
    "print(\"Top recommended items for user:\", top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on  whole testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game_video': 0, 'video_game': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt['domain_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++\n",
      "{'NDCG_10': 0.03627514009901053, 'HT_10': 0.07515337423312883}\n"
     ]
    }
   ],
   "source": [
    "metrics_01=model.predict(opt['domain_id']['game_video'],test_dataloader['game_video'])\n",
    "print(metrics_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++\n",
      "{'NDCG_10': 0.05837049329217823, 'HT_10': 0.11042524005486969}\n"
     ]
    }
   ],
   "source": [
    "metrics_10=model.predict(opt['domain_id']['video_game'],test_dataloader['video_game'])\n",
    "print(metrics_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metrics   | In paper (100 epochs) | Our replication (50 epochs) |\n",
    "|-----------|-----------------------|------------------------------|\n",
    "| HR@10     | 8.78                  | 11.04                         |\n",
    "| NDCG@10   | 4.63                    | 5.83                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
